{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "import analysis_util\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>version</th>\n",
       "      <th>period</th>\n",
       "      <th>total_activity</th>\n",
       "      <th>number_of_nodes</th>\n",
       "      <th>number_of_edges</th>\n",
       "      <th>average_weight_of_edges</th>\n",
       "      <th>median_weight_of_edges</th>\n",
       "      <th>average_degree</th>\n",
       "      <th>median_degree</th>\n",
       "      <th>average_clustering_coefficient</th>\n",
       "      <th>mean_activity</th>\n",
       "      <th>mean_delta_time</th>\n",
       "      <th>number_of_reciprocal_edges</th>\n",
       "      <th>fraction_of_reciprocal_edges</th>\n",
       "      <th>clustering_coefficient_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FourSentenceStories</td>\n",
       "      <td>2022-11-18 10:14:18</td>\n",
       "      <td>2021-05-04 - 2021-12-28</td>\n",
       "      <td>200</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>2.678571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.647059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274683</td>\n",
       "      <td>5.823529</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Trump666</td>\n",
       "      <td>2022-11-18 10:15:23</td>\n",
       "      <td>2020-03-16 - 2022-01-01</td>\n",
       "      <td>6746</td>\n",
       "      <td>755</td>\n",
       "      <td>1628</td>\n",
       "      <td>2.652948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.312583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.202507</td>\n",
       "      <td>7.909934</td>\n",
       "      <td>53</td>\n",
       "      <td>1048</td>\n",
       "      <td>0.492944</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GraphTheory</td>\n",
       "      <td>2022-11-18 10:18:32</td>\n",
       "      <td>2015-02-17 - 2021-12-26</td>\n",
       "      <td>497</td>\n",
       "      <td>247</td>\n",
       "      <td>163</td>\n",
       "      <td>1.717791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.319838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>2.012146</td>\n",
       "      <td>59</td>\n",
       "      <td>124</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jazznoir</td>\n",
       "      <td>2022-11-18 10:19:14</td>\n",
       "      <td>2015-01-01 - 2022-01-01</td>\n",
       "      <td>4725</td>\n",
       "      <td>1497</td>\n",
       "      <td>1139</td>\n",
       "      <td>1.474100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.521710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>2.985944</td>\n",
       "      <td>122</td>\n",
       "      <td>640</td>\n",
       "      <td>0.453258</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>indoorbouldering</td>\n",
       "      <td>2022-11-18 11:16:58</td>\n",
       "      <td>2017-08-23 - 2022-01-01</td>\n",
       "      <td>10532</td>\n",
       "      <td>2529</td>\n",
       "      <td>4866</td>\n",
       "      <td>1.665228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.848161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.061709</td>\n",
       "      <td>3.967181</td>\n",
       "      <td>112</td>\n",
       "      <td>3487</td>\n",
       "      <td>0.531960</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DTU</td>\n",
       "      <td>2022-11-18 11:22:59</td>\n",
       "      <td>2015-05-15 - 2022-01-01</td>\n",
       "      <td>2788</td>\n",
       "      <td>689</td>\n",
       "      <td>1196</td>\n",
       "      <td>1.805184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.471698</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.064316</td>\n",
       "      <td>4.046444</td>\n",
       "      <td>136</td>\n",
       "      <td>1014</td>\n",
       "      <td>0.600355</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kiwi_bird</td>\n",
       "      <td>2022-11-18 11:24:00</td>\n",
       "      <td>2015-02-21 - 2021-12-27</td>\n",
       "      <td>862</td>\n",
       "      <td>302</td>\n",
       "      <td>301</td>\n",
       "      <td>1.594684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.993377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>2.778146</td>\n",
       "      <td>65</td>\n",
       "      <td>128</td>\n",
       "      <td>0.357542</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit              version                   period  \\\n",
       "9   FourSentenceStories  2022-11-18 10:14:18  2021-05-04 - 2021-12-28   \n",
       "10             Trump666  2022-11-18 10:15:23  2020-03-16 - 2022-01-01   \n",
       "11          GraphTheory  2022-11-18 10:18:32  2015-02-17 - 2021-12-26   \n",
       "12             jazznoir  2022-11-18 10:19:14  2015-01-01 - 2022-01-01   \n",
       "13     indoorbouldering  2022-11-18 11:16:58  2017-08-23 - 2022-01-01   \n",
       "14                  DTU  2022-11-18 11:22:59  2015-05-15 - 2022-01-01   \n",
       "15            kiwi_bird  2022-11-18 11:24:00  2015-02-21 - 2021-12-27   \n",
       "\n",
       "    total_activity  number_of_nodes  number_of_edges  average_weight_of_edges  \\\n",
       "9              200               34               28                 2.678571   \n",
       "10            6746              755             1628                 2.652948   \n",
       "11             497              247              163                 1.717791   \n",
       "12            4725             1497             1139                 1.474100   \n",
       "13           10532             2529             4866                 1.665228   \n",
       "14            2788              689             1196                 1.805184   \n",
       "15             862              302              301                 1.594684   \n",
       "\n",
       "    median_weight_of_edges  average_degree  median_degree  \\\n",
       "9                      1.0        1.647059            1.0   \n",
       "10                     1.0        4.312583            2.0   \n",
       "11                     1.0        1.319838            1.0   \n",
       "12                     1.0        1.521710            1.0   \n",
       "13                     1.0        3.848161            2.0   \n",
       "14                     1.0        3.471698            2.0   \n",
       "15                     1.0        1.993377            1.0   \n",
       "\n",
       "    average_clustering_coefficient  mean_activity  mean_delta_time  \\\n",
       "9                         0.274683       5.823529               19   \n",
       "10                        0.202507       7.909934               53   \n",
       "11                        0.015602       2.012146               59   \n",
       "12                        0.009824       2.985944              122   \n",
       "13                        0.061709       3.967181              112   \n",
       "14                        0.064316       4.046444              136   \n",
       "15                        0.047712       2.778146               65   \n",
       "\n",
       "    number_of_reciprocal_edges  fraction_of_reciprocal_edges  \\\n",
       "9                           15                      0.428571   \n",
       "10                        1048                      0.492944   \n",
       "11                         124                      0.563636   \n",
       "12                         640                      0.453258   \n",
       "13                        3487                      0.531960   \n",
       "14                        1014                      0.600355   \n",
       "15                         128                      0.357542   \n",
       "\n",
       "    clustering_coefficient_p_value  \n",
       "9                            0.023  \n",
       "10                           0.000  \n",
       "11                           0.286  \n",
       "12                           0.016  \n",
       "13                           0.000  \n",
       "14                           0.000  \n",
       "15                           0.085  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/home/pelle/Master_Thesis/data/processed/community_metrics.csv').sort_values('number_of_nodes',ascending=False)\n",
    "# convert to int in days mean_delta_time\n",
    "df['mean_delta_time']=df['mean_delta_time'].apply(lambda x: int(x[:3]))\n",
    "\n",
    "# remove old versions of each subrredit\n",
    "def remove_old_versions(df):\n",
    "    df=df.sort_values('version')\n",
    "    df=df.drop_duplicates(subset=['subreddit'],keep='last')\n",
    "    return df\n",
    "\n",
    "df=remove_old_versions(df)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "          subreddit &                  period &   $A$ &  $N$ &  $E$ &  $\\overline{W}$ &  $W_{\\mu}$ &  $\\overline{D}$ &  $D_{\\mu}$ &  $\\overline{C}$ &  $\\overline{A}$ &  $\\overline{\\D t}$ &  $R$ &  $R_{\\%}$ &  $P_{C}$ \\\\\n",
      "\\midrule\n",
      "FourSentenceStories & 2021-05-04 - 2021-12-28 &   200 &   34 &   28 &           2.679 &        1.0 &           1.647 &        1.0 &           0.275 &           5.824 &                 19 &   15 &     0.429 &    0.023 \\\\\n",
      "           Trump666 & 2020-03-16 - 2022-01-01 &  6746 &  755 & 1628 &           2.653 &        1.0 &           4.313 &        2.0 &           0.203 &           7.910 &                 53 & 1048 &     0.493 &    0.000 \\\\\n",
      "        GraphTheory & 2015-02-17 - 2021-12-26 &   497 &  247 &  163 &           1.718 &        1.0 &           1.320 &        1.0 &           0.016 &           2.012 &                 59 &  124 &     0.564 &    0.286 \\\\\n",
      "           jazznoir & 2015-01-01 - 2022-01-01 &  4725 & 1497 & 1139 &           1.474 &        1.0 &           1.522 &        1.0 &           0.010 &           2.986 &                122 &  640 &     0.453 &    0.016 \\\\\n",
      "   indoorbouldering & 2017-08-23 - 2022-01-01 & 10532 & 2529 & 4866 &           1.665 &        1.0 &           3.848 &        2.0 &           0.062 &           3.967 &                112 & 3487 &     0.532 &    0.000 \\\\\n",
      "                DTU & 2015-05-15 - 2022-01-01 &  2788 &  689 & 1196 &           1.805 &        1.0 &           3.472 &        2.0 &           0.064 &           4.046 &                136 & 1014 &     0.600 &    0.000 \\\\\n",
      "          kiwi_bird & 2015-02-21 - 2021-12-27 &   862 &  302 &  301 &           1.595 &        1.0 &           1.993 &        1.0 &           0.048 &           2.778 &                 65 &  128 &     0.358 &    0.085 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'mean_delta_time':'$\\overline{\\D t}$'},inplace=True)\n",
    "df.rename(columns={'number_of_nodes':'$N$'},inplace=True)\n",
    "df.rename(columns={'number_of_edges':'$E$'},inplace=True)\n",
    "df.rename(columns={'total_activity': '$A$'},inplace=True)\n",
    "df.rename(columns={'mean_activity': '$\\overline{A}$'},inplace=True)\n",
    "df.rename(columns={'mean_degree': '$\\overline{D}$'},inplace=True)\n",
    "df.rename(columns={'median_degree': '$D_{\\mu}$'},inplace=True)\n",
    "df.rename(columns={'average_clustering_coefficient': '$\\overline{C}$'},inplace=True)\n",
    "df.rename(columns={'average_weight_of_edges': '$\\overline{W}$'},inplace=True)\n",
    "df.rename(columns={'median_weight_oaverage_degreef_edges': '$W_{\\mu}$'},inplace=True)\n",
    "df.rename(columns={'average_degree': '$\\overline{D}$'},inplace=True)\n",
    "df.rename(columns={'number_of_reciprocal_edges': '$R$'},inplace=True)\n",
    "df.rename(columns={'fraction_of_reciprocal_edges': '$R_{\\%}$'},inplace=True)\n",
    "df.rename(columns={'clustering_coefficient_p_value': '$P_{C}$'},inplace=True)\n",
    "df.rename(columns={'median_weight_of_edges': '$W_{\\mu}$'},inplace=True)\n",
    "\n",
    "print(df.drop(columns=['version']).round(decimals=3).to_latex(escape=False,index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>indoorbouldering</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jazznoir</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump666</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTU</th>\n",
       "      <td>A research university in Denmark, with a focus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kiwi_bird</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GraphTheory</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourSentenceStories</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           explanation\n",
       "subreddit                                                             \n",
       "indoorbouldering                                                     0\n",
       "jazznoir                                                             0\n",
       "Trump666                                                             0\n",
       "DTU                  A research university in Denmark, with a focus...\n",
       "kiwi_bird                                                            0\n",
       "GraphTheory                                                          0\n",
       "FourSentenceStories                                                  0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_explanation=pd.DataFrame(df['subreddit']).set_index('subreddit')\n",
    "\n",
    "# df_explanation['DTU']['xx']\n",
    "\n",
    "# new collumns for explanation\n",
    "df_explanation['explanation']=0\n",
    "df_explanation['explanation']['DTU'] = \"A subreddit related to the technical university of Denmark DTU\"\n",
    "df_explanation['explanation']['jazznoir'] = \"\"\n",
    "\n",
    "\n",
    "df_explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Done loading data..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1231826"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import praw\n",
    "\n",
    "print(\"Reading data...\")\n",
    "sample = pd.read_csv('/home/pelle/Master_Thesis/data/raw/wallstreetbets/submissions_pmaw_2016-2021_wsb.csv',nrows=10)\n",
    "dtypes = sample.dtypes # Get the dtypes\n",
    "cols = sample.columns # Get the columns\n",
    "dtype_dictionary = {} \n",
    "for c in cols:\n",
    "    if str(dtypes[c]) == 'int64':\n",
    "        dtype_dictionary[c] = 'float32' # Handle NANs in int columns\n",
    "    else:\n",
    "        dtype_dictionary[c] = str(dtypes[c])\n",
    "\n",
    "df_posts = pd.read_csv('/home/pelle/Master_Thesis/data/raw/wallstreetbets/submissions_pmaw_2016-2021_wsb.csv',dtype=dtype_dictionary, \n",
    "                keep_default_na=False,\n",
    "                na_values=['na',''],\n",
    "                usecols=['id'])\n",
    "\n",
    "print('Done loading data..' )\n",
    "\n",
    "len(df_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 103261: expected 2 fields, saw 3\\nSkipping line 103715: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 105563: expected 2 fields, saw 3\\nSkipping line 224290: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 174197: expected 2 fields, saw 3\\nSkipping line 177835: expected 2 fields, saw 3\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970329\n",
      "701367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 104652: expected 2 fields, saw 3\\nSkipping line 223379: expected 2 fields, saw 3\\n'\n"
     ]
    }
   ],
   "source": [
    "p = '/home/pelle/Master_Thesis/data/awards/wallstreetbets/'\n",
    "files = os.listdir(p)\n",
    "\n",
    "df_awards = pd.DataFrame()\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(p+f,error_bad_lines=False,header=None, names=['id','award_count'])\n",
    "\n",
    "    df_awards = pd.concat([df_awards,df],ignore_index=True)\n",
    "\n",
    "print(len(df_awards))\n",
    "df_awards = df_awards.drop_duplicates(subset=['id'])\n",
    "print(len(df_awards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>award_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>l8tfi8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>l8tf06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>l8tu2m</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>l8tsv4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>l8s1h4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745906</th>\n",
       "      <td>l7ge7g</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852521</th>\n",
       "      <td>go07dw</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968991</th>\n",
       "      <td>fsypwh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969034</th>\n",
       "      <td>fe5s7e</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970306</th>\n",
       "      <td>fhk4pn</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17862 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  award_count\n",
       "167     l8tfi8          3.0\n",
       "204     l8tf06          1.0\n",
       "244     l8tu2m          2.0\n",
       "335     l8tsv4          7.0\n",
       "379     l8s1h4          2.0\n",
       "...        ...          ...\n",
       "745906  l7ge7g          2.0\n",
       "852521  go07dw          1.0\n",
       "968991  fsypwh          1.0\n",
       "969034  fe5s7e         60.0\n",
       "970306  fhk4pn          1.0\n",
       "\n",
       "[17862 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_awards.loc[df_awards['award_count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def get_periods(tstart, tend, interval):\n",
    "    periods = []\n",
    "\n",
    "    period_start = tstart\n",
    "    while period_start < tend:\n",
    "        period_end = min(period_start + interval, tend)\n",
    "        periods.append((\n",
    "            int(period_start.timestamp()), \n",
    "            int(period_end.timestamp())\n",
    "            ))\n",
    "        period_start = period_end\n",
    "\n",
    "    return periods\n",
    "\n",
    "\n",
    "def convert_utc_to_date(df):\n",
    "    df['date'] = pd.to_datetime(df['created'],unit='s')\n",
    "    return df\n",
    "\n",
    "def download_comments(start,end,subreddit,limit):\n",
    "\n",
    "    def data_prep_comments(subreddit, start_time, end_time, filters, limit):\n",
    "        if (len(filters) == 0):\n",
    "            filters = ['id', 'author', 'created_utc','total_awards_received']\n",
    "                    #We set by default some usefull columns \n",
    "\n",
    "        comments = list(api.search_comments(\n",
    "            subreddit=subreddit,    #Subreddit we want to audit\n",
    "            after=start_time,       #Start date\n",
    "            before=end_time,        #End date\n",
    "            filter=filters,         #Column names we want to retrieve\n",
    "            limit=limit,\n",
    "            total_awards_received = \">0\"))       #Max number of comments\n",
    "        return pd.DataFrame([thing.d_ for thing in comments]) #Return dataframe for analysis\n",
    "    \n",
    "    print('Setting up API..')\n",
    "    api = PushshiftAPI()\n",
    "\n",
    "    periods = get_periods(start, end, dt.timedelta(days=2))\n",
    "\n",
    "    for period in tqdm(periods):\n",
    "        df_c = data_prep_comments(subreddit, start_time=period[0], end_time=period[1], filters=[], limit=limit)\n",
    "        # wait N second to avoid rate limit\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import current_thread\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def convert_utc_to_date(df):\n",
    "    df['date'] = pd.to_datetime(df['date'],unit='s')\n",
    "    return df\n",
    "\n",
    "def data_prep_posts(subreddit, start_time, end_time,  limit,api):\n",
    "    filters = ['id', 'author', 'created_utc','total_awards_received']              \n",
    "                #We set by default some useful columns\n",
    "\n",
    "    posts = list(api.search_submissions(\n",
    "        subreddit=subreddit,   #Subreddit we want to audit\n",
    "        after=start_time,      #Start date\n",
    "        before=end_time,       #End date\n",
    "        filter=filters,        #Column names we want to retrieve\n",
    "        limit=limit))      #Max number of comments))          \n",
    "\n",
    "    return pd.DataFrame([thing.d_ for thing in posts])\n",
    "\n",
    "\n",
    "def download_posts(start,end,subreddit,folder_name,file_name,limit,check_point):\n",
    "    # if file_name == None: file_name = subreddit\n",
    "\n",
    "    # if check_point:\n",
    "    #     print('Continuing from last checkpoint..')\n",
    "    #     current_df = pd.read_csv(\"./data/raw/\" + folder_name + '/' + file_name + \".csv\")\n",
    "    #     current_df.columns = ['author','created_utc','domain','id','n_comments','score','text','title','url','date']\n",
    "    #     current_df.drop(current_df.loc[current_df['date'].apply(lambda x: isinstance(x, str))].index, inplace=True)\n",
    "    #     current_df = convert_utc_to_date(current_df)\n",
    "    #     start = current_df.date.max()\n",
    "    # else: \n",
    "    #     print('Starting from scratch..')\n",
    "    #     pd.DataFrame().to_csv(\"./data/raw/\" + folder_name + '/' + file_name + \".csv\", index=False, header=False)\n",
    "    \n",
    "    delta = end - start\n",
    "    # print('Downloading to..: ', file_name+'.csv')\n",
    "    # print('Start date: ' + str(start))\n",
    "    # print('End date: ' + str(end))\n",
    "    # print('Subreddit: ' + subreddit)\n",
    "    \n",
    "    print('Setting up API..')\n",
    "    api = PushshiftAPI()\n",
    "\n",
    "    print('Starting..') \n",
    "    for d in tqdm(range(delta.days + 1)):\n",
    "        d_1=dt.timedelta(days=1)\n",
    "        d_n=dt.timedelta(days=d+1)\n",
    "        start_get=int((start+d_n-d_1).timestamp())\n",
    "        end_get=int((start+d_n).timestamp())\n",
    "        \n",
    "        df=data_prep_posts(subreddit,start_get,end_get,limit,api)\n",
    "        # df.to_csv(\"./data/raw/\" + folder_name + '/' +  file_name + \".csv\", mode='a', index=False, header=False)\n",
    "        # wait N second to avoid rate limit\n",
    "        sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Unable to connect to pushshift.io. Max retries exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5405/747076327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPushshiftAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_prep_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DTU'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, r, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mshards_down_behavior\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_retries, max_sleep, backoff, rate_limit_per_minute, max_results_per_request, detect_local_tz, utc_offset_secs, domain, https_proxy, shards_down_behavior)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrate_limit_per_minute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connecting to /meta endpoint to learn rate limit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mrate_limit_per_minute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server_ratelimit_per_minute'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"server_ratelimit_per_minute: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrate_limit_per_minute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, payload)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got non 200 code %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to connect to pushshift.io. Max retries exceeded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Unable to connect to pushshift.io. Max retries exceeded."
     ]
    }
   ],
   "source": [
    "start=dt.datetime(year=2015, month=1, day=1)\n",
    "end=dt.datetime(year=2015, month=1, day=2)\n",
    "api = PushshiftAPI()\n",
    "\n",
    "df=data_prep_posts('DTU',start,end,None,api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"https://www.reddit.com/r/pics/comments/zp5c42/elon_musk_hanging_out_with_jared_kushner_at_the/\"\n",
    "\n",
    "response = request.urlopen(url)\n",
    "# set the correct charset below\n",
    "page_source = response.read().decode('utf-8')\n",
    "type(page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "req = requests.get(url, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5405/1690923004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#     print(span.string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import bs4\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "url = \"https://www.reddit.com/r/pics/comments/zp5c42/elon_musk_hanging_out_with_jared_kushner_at_the/\"\n",
    "\n",
    "driver_location = '/usr/bin/chromedriver'\n",
    "binary_location = '/usr/bin/google-chrome'\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = binary_location\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=driver_location,options=options)\n",
    "driver.get(url)\n",
    "\n",
    "innerHTML = driver.execute_script(\"return document.body.innerHTML\")\n",
    "##print(driver.page_source)\n",
    "\n",
    "sleep(1)\n",
    "root=bs4.BeautifulSoup(innerHTML,\"lxml\")\n",
    "viewcount=root.find_all(\"span\",attrs={'class':'short-view-count style-scope yt-view-count-renderer'})\n",
    "\n",
    "\n",
    "# for span in viewcount:\n",
    "#     print(span.string)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "reg=re.findall(r\"(?<=data-count=.)\\d\", innerHTML)\n",
    "reg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1f814a4e109c882a9affb42993ee939858e43ebdc57bfb1498f07e0b82aab6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
